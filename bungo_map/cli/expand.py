#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒ‡ãƒ¼ã‚¿æ‹¡å……CLI - å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿æ‹¡å……æ©Ÿèƒ½
"""

import argparse
import time
from typing import List, Dict
import sys
import os

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
sys.path.insert(0, project_root)

from bungo_map.core.database import BungoDatabase
from bungo_map.extractors.wikipedia_extractor import WikipediaExtractor
from bungo_map.extractors.aozora_extractor import AozoraExtractor


class DataExpansionEngine:
    """ãƒ‡ãƒ¼ã‚¿æ‹¡å……ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, db_path: str = "data/bungo_production.db"):
        self.db = BungoDatabase(db_path)
        self.wiki_extractor = WikipediaExtractor()
        self.aozora_extractor = AozoraExtractor()
        
    def expand_authors(self, target_count: int = 30, test_mode: bool = False) -> Dict:
        """ä½œè€…ãƒ‡ãƒ¼ã‚¿ã‚’æ‹¡å……ã™ã‚‹"""
        print(f"\nğŸš€ **ä½œè€…ãƒ‡ãƒ¼ã‚¿æ‹¡å……é–‹å§‹** (ç›®æ¨™: {target_count}å)")
        
        start_time = time.time()
        
        # ç¾åœ¨ã®ä½œè€…æ•°ç¢ºèªï¼ˆå…¨ä½œè€…æ¤œç´¢ã§å–å¾—ï¼‰
        current_authors = self.db.search_authors("", limit=1000)  # ç©ºæ–‡å­—ã§å…¨ä½œè€…æ¤œç´¢
        current_count = len(current_authors)
        print(f"ğŸ“Š ç¾åœ¨ã®ä½œè€…æ•°: {current_count}å")
        
        if current_count >= target_count:
            print(f"âœ… æ—¢ã«ç›®æ¨™æ•°ã«é”ã—ã¦ã„ã¾ã™ ({current_count} >= {target_count})")
            return {"status": "already_sufficient", "current_count": current_count}
        
        # è‘—åæ–‡è±ªãƒªã‚¹ãƒˆå–å¾—
        famous_authors = self.wiki_extractor.get_famous_authors_list()
        
        # æ—¢å­˜ä½œè€…åã‚»ãƒƒãƒˆ
        existing_names = {author['name'] for author in current_authors}
        
        # æ–°è¦è¿½åŠ å¯¾è±¡ã®ä½œè€…
        new_authors = [name for name in famous_authors if name not in existing_names]
        needed_count = target_count - current_count
        
        if test_mode:
            new_authors = new_authors[:3]  # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§ã¯3åã¾ã§
            
        target_authors = new_authors[:needed_count]
        
        print(f"ğŸ“ æ–°è¦è¿½åŠ äºˆå®š: {len(target_authors)}å")
        print(f"   {', '.join(target_authors)}")
        
        success_count = 0
        results = []
        
        for i, author_name in enumerate(target_authors, 1):
            print(f"\n[{i}/{len(target_authors)}] {author_name} ã‚’å‡¦ç†ä¸­...")
            
            try:
                # ä½œè€…æƒ…å ±ã‚’Wikipediaã‹ã‚‰æŠ½å‡º
                author_data = self.wiki_extractor.extract_author_data(author_name)
                
                if author_data:
                    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä½œè€…ã‚’è¿½åŠ 
                    author_id = self.db.insert_author(author_data)
                    
                    if author_id:
                        # ä½œå“æƒ…å ±ã‚’æŠ½å‡º
                        works_data = self.wiki_extractor.extract_works_data(author_id, author_name, limit=10)
                        
                        # ä½œå“ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ 
                        work_count = 0
                        for work in works_data:
                            work_id = self.db.insert_work(work)
                            if work_id:
                                work_count += 1
                        
                        success_count += 1
                        result = {
                            'author_name': author_name,
                            'author_id': author_id,
                            'works_added': work_count,
                            'status': 'success'
                        }
                        results.append(result)
                        
                        print(f"âœ… {author_name}: ä½œè€…è¿½åŠ å®Œäº†, {work_count}ä½œå“è¿½åŠ ")
                    else:
                        print(f"âŒ {author_name}: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æŒ¿å…¥å¤±æ•—")
                        results.append({'author_name': author_name, 'status': 'db_error'})
                else:
                    print(f"âŒ {author_name}: Wikipediaæƒ…å ±å–å¾—å¤±æ•—")
                    results.append({'author_name': author_name, 'status': 'extraction_error'})
                    
            except Exception as e:
                print(f"âŒ {author_name}: ã‚¨ãƒ©ãƒ¼ - {e}")
                results.append({'author_name': author_name, 'status': 'error', 'error': str(e)})
            
            # APIåˆ¶é™å¯¾ç­–: å°‘ã—å¾…æ©Ÿ
            time.sleep(1)
        
        end_time = time.time()
        
        # æœ€çµ‚çµæœ
        final_authors = self.db.search_authors("", limit=1000)
        final_count = len(final_authors)
        
        summary = {
            'initial_count': current_count,
            'target_count': target_count,
            'final_count': final_count,
            'success_count': success_count,
            'failed_count': len(target_authors) - success_count,
            'execution_time': round(end_time - start_time, 2),
            'results': results
        }
        
        print(f"\nğŸ‰ **ä½œè€…ãƒ‡ãƒ¼ã‚¿æ‹¡å……å®Œäº†**")
        print(f"   é–‹å§‹æ™‚: {current_count}å â†’ å®Œäº†æ™‚: {final_count}å")
        print(f"   æˆåŠŸ: {success_count}å, å¤±æ•—: {len(target_authors) - success_count}å")
        print(f"   å®Ÿè¡Œæ™‚é–“: {summary['execution_time']}ç§’")
        
        return summary
    
    def expand_places_for_author(self, author_name: str, force_update: bool = False) -> Dict:
        """ç‰¹å®šä½œè€…ã®åœ°åãƒ‡ãƒ¼ã‚¿ã‚’æ‹¡å……ã™ã‚‹"""
        print(f"\nğŸ“ {author_name} ã®åœ°åãƒ‡ãƒ¼ã‚¿æ‹¡å……é–‹å§‹...")
        
        start_time = time.time()
        
        # ä½œè€…æƒ…å ±å–å¾—
        authors = self.db.search_authors(author_name)
        if not authors:
            print(f"âŒ ä½œè€…ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {author_name}")
            return {"status": "author_not_found"}
        
        author = authors[0]
        
        # ä½œè€…ã®ä½œå“ã‚’å–å¾—
        works = self.db.get_works_by_author(author.author_id)
        print(f"ğŸ“š {author.name} ã®ä½œå“æ•°: {len(works)}ä½œå“")
        
        total_places_added = 0
        results = []
        
        for work in works:
            print(f"\n   ğŸ“– {work.title} ã‚’å‡¦ç†ä¸­...")
            
            try:
                # æ—¢å­˜ã®åœ°åæ•°ç¢ºèª
                existing_places = self.db.get_places_by_work(work.work_id)
                
                if existing_places and not force_update:
                    print(f"      â­ï¸  æ—¢ã«{len(existing_places)}åœ°åã‚ã‚Šï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
                    continue
                
                # é’ç©ºæ–‡åº«ã‹ã‚‰æœ¬æ–‡å–å¾—
                aozora_url = self.aozora_extractor.search_aozora_work(work['title'], author['name'])
                
                if aozora_url:
                    print(f"      ğŸ“¥ é’ç©ºæ–‡åº«ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
                    text_content = self.aozora_extractor.download_and_extract_text(aozora_url)
                    
                    if text_content:
                        print(f"      âœ… ãƒ†ã‚­ã‚¹ãƒˆå–å¾—æˆåŠŸ: {len(text_content)}æ–‡å­—")
                        # TODO: GiNZAã§åœ°åæŠ½å‡ºï¼ˆæ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã§å®Ÿè£…ï¼‰
                        print(f"      âš ï¸ åœ°åæŠ½å‡ºæ©Ÿèƒ½ã¯æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã§å®Ÿè£…äºˆå®š")
                        
                        result = {
                            'work_title': work['title'],
                            'places_added': 0,
                            'text_length': len(text_content),
                            'status': 'text_ready'
                        }
                        results.append(result)
                    else:
                        print(f"      âŒ æœ¬æ–‡å–å¾—å¤±æ•—")
                        results.append({'work_title': work['title'], 'status': 'text_error'})
                else:
                    print(f"      âŒ é’ç©ºæ–‡åº«URLå–å¾—å¤±æ•—")
                    results.append({'work_title': work['title'], 'status': 'url_error'})
                    
            except Exception as e:
                print(f"      âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                results.append({'work_title': work.title, 'status': 'error', 'error': str(e)})
            
            # APIåˆ¶é™å¯¾ç­–
            time.sleep(2)
        
        end_time = time.time()
        
        summary = {
            'author_name': author.name,
            'works_processed': len(works),
            'total_places_added': total_places_added,
            'execution_time': round(end_time - start_time, 2),
            'results': results
        }
        
        print(f"\nâœ… {author.name} ã®åœ°åãƒ‡ãƒ¼ã‚¿æ‹¡å……å®Œäº†")
        print(f"   å‡¦ç†ä½œå“: {len(works)}ä½œå“")
        print(f"   è¿½åŠ åœ°å: {total_places_added}ç®‡æ‰€")
        print(f"   å®Ÿè¡Œæ™‚é–“: {summary['execution_time']}ç§’")
        
        return summary
    
    def test_wikipedia_extraction(self, author_names: List[str] = None) -> Dict:
        """WikipediaæŠ½å‡ºæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
        if not author_names:
            author_names = ["å¤ç›®æ¼±çŸ³", "æ£®é´å¤–", "å·ç«¯åº·æˆ"]
        
        print(f"\nğŸ§ª **WikipediaæŠ½å‡ºãƒ†ã‚¹ãƒˆ** ({len(author_names)}å)")
        
        results = []
        for author_name in author_names:
            result = self.wiki_extractor.test_extraction(author_name)
            results.append(result)
            
            # çµæœè¡¨ç¤º
            print(f"\nğŸ“‹ {author_name} ã®çµæœ:")
            print(f"   Wikipedia URL: {result['author_data']['wikipedia_url']}")
            print(f"   ç”Ÿæ²¡å¹´: {result['author_data']['birth_year']} - {result['author_data']['death_year']}")
            print(f"   ä½œå“æ•°: {result['works_count']}")
            print(f"   ä½œå“: {', '.join(result['works'][:3])}{'...' if len(result['works']) > 3 else ''}")
        
        return {
            'test_authors': author_names,
            'results': results,
            'total_time': sum(r['extraction_time'] for r in results)
        }
    
    def test_aozora_extraction(self, work_samples: List[Dict] = None) -> Dict:
        """é’ç©ºæ–‡åº«æŠ½å‡ºæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
        if not work_samples:
            work_samples = self.aozora_extractor.get_sample_works()
        
        print(f"\nğŸŒ¸ **é’ç©ºæ–‡åº«æŠ½å‡ºãƒ†ã‚¹ãƒˆ** ({len(work_samples)}ä½œå“)")
        
        results = []
        for work_info in work_samples:
            result = self.aozora_extractor.test_extraction(work_info)
            results.append(result)
            
            # çµæœè¡¨ç¤º
            print(f"\nğŸ“– {result['author_name']} - {result['title']} ã®çµæœ:")
            print(f"   æˆåŠŸ: {'âœ…' if result['success'] else 'âŒ'}")
            if result['success']:
                print(f"   ãƒ†ã‚­ã‚¹ãƒˆé•·: {result['text_length']:,}æ–‡å­—")
                print(f"   ã‚µãƒ³ãƒ—ãƒ«: {result['sample_text']}")
            print(f"   å®Ÿè¡Œæ™‚é–“: {result['extraction_time']}ç§’")
        
        return {
            'test_works': work_samples,
            'results': results,
            'success_rate': sum(1 for r in results if r['success']) / len(results) * 100,
            'total_time': sum(r['extraction_time'] for r in results)
        }
    
    def show_current_status(self) -> Dict:
        """ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ³ã‚’è¡¨ç¤º"""
        print(f"\nğŸ“Š **ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ³**")
        
        authors = self.db.search_authors("", limit=1000)
        total_works = 0
        total_places = 0
        
        for author in authors:
            works = self.db.get_works_by_author(author['author_id'])
            total_works += len(works)
            
            for work in works:
                places = self.db.get_places_by_work(work['work_id'])
                total_places += len(places)
        
        status = {
            'authors_count': len(authors),
            'works_count': total_works,
            'places_count': total_places
        }
        
        print(f"   ä½œè€…æ•°: {status['authors_count']}å")
        print(f"   ä½œå“æ•°: {status['works_count']}ä½œå“")
        print(f"   åœ°åæ•°: {status['places_count']}ç®‡æ‰€")
        
        # ä½œè€…ä¸€è¦§è¡¨ç¤º
        if authors:
            print(f"\nğŸ“ ç™»éŒ²ä½œè€…ä¸€è¦§:")
            for i, author in enumerate(authors[:10], 1):
                works_count = len(self.db.get_works_by_author(author['author_id']))
                birth_info = f"({author['birth_year']}-{author['death_year']})" if author['birth_year'] else ""
                print(f"   {i:2d}. {author['name']} {birth_info} - {works_count}ä½œå“")
            
            if len(authors) > 10:
                print(f"   ... ä»–{len(authors)-10}å")
        
        return status


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description='æ–‡è±ªãƒ‡ãƒ¼ã‚¿æ‹¡å……ãƒ„ãƒ¼ãƒ«')
    parser.add_argument('command', choices=['authors', 'places', 'test', 'status'], 
                       help='å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰')
    parser.add_argument('--target', type=int, default=30, 
                       help='ç›®æ¨™ä½œè€…æ•° (authorsã‚³ãƒãƒ³ãƒ‰ç”¨)')
    parser.add_argument('--author', type=str, 
                       help='å¯¾è±¡ä½œè€…å (placesã‚³ãƒãƒ³ãƒ‰ç”¨)')
    parser.add_argument('--force', action='store_true', 
                       help='å¼·åˆ¶æ›´æ–°')
    parser.add_argument('--test-mode', action='store_true',
                       help='ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼ˆå°‘é‡ãƒ‡ãƒ¼ã‚¿ã§å®Ÿè¡Œï¼‰')
    parser.add_argument('--db-path', type=str, default="data/bungo_production.db",
                       help='ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    
    args = parser.parse_args()
    
    # ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
    engine = DataExpansionEngine(args.db_path)
    
    # ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ
    if args.command == 'authors':
        result = engine.expand_authors(args.target, args.test_mode)
        
    elif args.command == 'places':
        if not args.author:
            print("âŒ --author ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ä½œè€…åã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
            return
        result = engine.expand_places_for_author(args.author, args.force)
        
    elif args.command == 'test':
        result = engine.test_wikipedia_extraction()
        
    elif args.command == 'status':
        result = engine.show_current_status()
    
    print(f"\nğŸ¯ **å®Ÿè¡Œå®Œäº†**")


if __name__ == "__main__":
    main() 
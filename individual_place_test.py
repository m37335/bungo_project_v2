#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å€‹åˆ¥åœ°åæ¤œå‡ºãƒ†ã‚¹ãƒˆ
"""

import spacy

def test_individual_places():
    """å€‹åˆ¥åœ°åã®æ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
    print("ğŸ”¬ å€‹åˆ¥åœ°åæ¤œå‡ºãƒ†ã‚¹ãƒˆ")
    print("=" * 40)
    
    nlp = spacy.load('ja_core_news_sm')
    
    test_cases = [
        "ç§ã¯å¤ä¼‘ã¿ã«éŒå€‰ã®æµ·å²¸ã§å…ˆç”Ÿã¨å‡ºä¼šã£ãŸã€‚",
        "å…ˆç”Ÿã®å®¶ã¯æœ¬éƒ·ã«ã‚ã£ãŸã€‚",
        "æ±½è»ŠãŒæ¾å±±å¸‚ã«ç€ã„ãŸã€‚",
        "äº¬éƒ½ã®ç¾…ç”Ÿé–€ã®ä¸‹ã§é›¨ã‚„ã¿ã‚’å¾…ã£ã¦ã„ãŸã€‚",
        "æ±äº¬ã«æˆ»ã‚‹ã¨ã€å…ˆç”Ÿã¨ã®æ–‡é€šãŒå§‹ã¾ã£ãŸã€‚",
        "ã‚·ãƒ©ã‚¯ã‚¹ã®å¸‚ã«å‡ºã¦æ¥ã¦ã€ç‹ã®ä¸ä¿¡ã‚’ç¢ºä¿¡ã—ãŸã€‚"
    ]
    
    for i, text in enumerate(test_cases, 1):
        print(f"\n{i}. ãƒ†ã‚¹ãƒˆ: {text}")
        doc = nlp(text)
        
        # å…¨å›ºæœ‰è¡¨ç¾
        all_entities = [(ent.text, ent.label_) for ent in doc.ents]
        print(f"   å…¨å›ºæœ‰è¡¨ç¾: {all_entities}")
        
        # åœ°åã®ã¿
        places = [(ent.text, ent.label_) for ent in doc.ents if ent.label_ in ['GPE', 'LOC']]
        if places:
            print(f"   âœ… åœ°å: {places}")
        else:
            print("   âŒ åœ°åæ¤œå‡ºãªã—")
        
        # ãƒˆãƒ¼ã‚¯ãƒ³åˆ†æ
        tokens = [(token.text, token.pos_, token.tag_) for token in doc]
        print(f"   ãƒˆãƒ¼ã‚¯ãƒ³: {tokens}")

if __name__ == "__main__":
    test_individual_places() 